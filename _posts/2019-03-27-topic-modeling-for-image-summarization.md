---
layout: post
title:  "Суммаризация изображений с использованием тематического моделирования"
date:   2019-03-27
desc: "Суммаризация изображений с использованием тематического моделирования"
keywords: "image processing, topic modeling, summarization, translation"
categories: [image processing, topic modeling, summarization, translation]
tags: [image processing, topic modeling, summarization, translation]
icon: icon-html
---

[Оригинальная статья](https://ieeexplore.ieee.org/document/7412194)

# Abstract

<p onmousedown="this.innerHTML='With the rapid advancement in technology it is easy to take pictures, and easier still to share them with the world at large. In this digital age the image data we have has grown manifold over the past few years. Digital Cameras have allowed the capturing and storing of large number of images highly inexpensive and hence we can’t go on a trip without taking several hundreds of photographs. We take repeated shots till we find the perfect one. As a result, in a collection of images we end up having recurring and similar images which we would like to omit. Manually going through such a huge collection and picking out the best images is a highly laborious task. This paper deals with devising a way of summarizing a given collection of photographs to represent a distinct set of representative images. This would save the users a lot of effort while allowing the selection of the best images of the set which also represent the entire set. Here we employ a modified Latent Dirichlet Allocation technique, a generative probabilistic model, to partition the images from a ’Bag of words’ representation created using Scale Invariant Feature Transform (SIFT) vectors and then clustering these vectors into bins. We validate the results using subjective analysis based on 3 metrics by the people providing the image collection and also by a more general set of people.'" onmouseout="this.innerHTML='Благодаря быстрому прогрессу в технологиях легко фотографировать, и еще проще делиться ими со всем миром. В наш цифровой век данные об изображениях, которые мы получили, выросли в разы за последние несколько лет. Цифровые камеры позволили снимать и хранить большое количество изображений без особых усилий, и поэтому мы не можем отправиться в путешествие, не сделав несколько сотен фотографий. Мы делаем повторные снимки, пока не найдем идеальный. В результате в коллекции изображений мы получаем повторяющиеся и похожие изображения, которые мы хотели бы опустить. Вручную просмотреть такую огромную коллекцию и выбрать лучшие изображения - очень трудоемкая задача. Эта статья посвящена разработке способа суммирования данной коллекции фотографий для представления отдельного набора репрезентативных изображений. Это сэкономит пользователям много усилий, позволяя выбирать лучшие изображения из набора, которые также представляют весь набор. Здесь мы используем модифицированный метод латентного размещения Дирихле, чтобы разделить изображения используя представление «Мешок слов», созданного с использованием векторов, получаемых из Scale Invariant Feature Transform (SIFT), а затем сгруппировать эти векторы в кластеры. Мы проверяем результаты, используя субъективный анализ, основанный на 3 метриках людьми, обеспечивающими сбор изображений, а также более общим набором людей.'">Благодаря быстрому прогрессу в технологиях легко фотографировать, и еще проще делиться ими со всем миром. В наш цифровой век данные об изображениях, которые мы получили, выросли в разы за последние несколько лет. Цифровые камеры позволили снимать и хранить большое количество изображений без особых усилий, и поэтому мы не можем отправиться в путешествие, не сделав несколько сотен фотографий. Мы делаем повторные снимки, пока не найдем идеальный. В результате в коллекции изображений мы получаем повторяющиеся и похожие изображения, которые мы хотели бы опустить. Вручную просмотреть такую огромную коллекцию и выбрать лучшие изображения - очень трудоемкая задача. Эта статья посвящена разработке способа суммирования данной коллекции фотографий для представления отдельного набора репрезентативных изображений. Это сэкономит пользователям много усилий, позволяя выбирать лучшие изображения из набора, которые также представляют весь набор. Здесь мы используем модифицированный метод латентного размещения Дирихле, чтобы разделить изображения используя представление «Мешок слов», созданного с использованием векторов, получаемых из Scale Invariant Feature Transform (SIFT), а затем сгруппировать эти векторы в кластеры. Мы проверяем результаты, используя субъективный анализ, основанный на 3 метриках людьми, обеспечивающими сбор изображений, а также более общим набором людей.</p>

## Введение
<p onmousedown="this.innerHTML='The number of photographs being uploaded online is growing at an unprecedented rate. A recent estimate is that 500 million images are uploaded to the internet every day (just considering Flickr, Facebook, Instagram and Snapchat), a figure which is expected to double every year. [1]'" onmouseout="this.innerHTML='Количество загружаемых фотографий в интернет растет беспрецедентными темпами. По последним оценкам, 500 миллионов изображений загружаются в Интернет каждый день (только в Flickr, Facebook, Instagram и Snapchat), и эта цифра, как ожидается, будет удваиваться каждый год. [1]'">Количество загружаемых фотографий в интернет растет беспрецедентными темпами. По последним оценкам, 500 миллионов изображений загружаются в Интернет каждый день (только в Flickr, Facebook, Instagram и Snapchat), и эта цифра, как ожидается, будет удваиваться каждый год. [1]</p>

<p onmousedown="this.innerHTML='Nowadays it is common for consumers to buy digital camera and take thousands of photos of daily life. Photographers have a tendency of capturing every moment and thus take multiple photos of a scene leading to a lot of redundant images. At the end a user is left with the task of managing large number of photographs after each trip. After each trip a user, manually goes through all photos, identifies similar photographs and selects the best. Since all the tasks are manually performed by users, this work is very burdensome and time consuming. In order to assist the user, we propose an automatic image summarization technique.'" onmouseout="this.innerHTML='В наши дни потребители часто покупают цифровые фотоаппараты и делают тысячи фотографий повседневной жизни. Фотографы имеют тенденцию запечатлеть каждый момент и, таким образом, сделать несколько фотографий сцены, что приводит к большому количеству избыточных изображений. В конце пользователь остается с задачей управления большим количеством фотографий после каждой поездки. После каждой поездки он или она вручную просматривает все фотографии, идентифицирует похожие фотографии и выбирает лучшие. Поскольку все задачи выполняются пользователями вручную, эта работа очень обременительна и требует много времени.Чтобы помочь людям, мы предлагаем метод автоматического суммирования изображений.'">В наши дни потребители часто покупают цифровые фотоаппараты и делают тысячи фотографий повседневной жизни. Фотографы имеют тенденцию запечатлеть каждый момент и, таким образом, сделать несколько фотографий сцены, что приводит к большому количеству избыточных изображений. В конце пользователь остается с задачей управления большим количеством фотографий после каждой поездки. После каждой поездки он или она вручную просматривает все фотографии, идентифицирует похожие фотографии и выбирает лучшие. Поскольку все задачи выполняются пользователями вручную, эта работа очень обременительна и требует много времени.Чтобы помочь людям, мы предлагаем метод автоматического суммирования изображений.</p>

<p onmousedown="this.innerHTML='We begin by defining some terminology. Throughout the paper, we use the term photo interchangeably with image and view, all of which refer to an ordinary 2D image. We define a collection as a set of photos. In its most basic form, a summary is a set of photos that represents the most interesting visual content of a collection of images.'" onmouseout="this.innerHTML='Мы начнем с определения некоторой терминологии. На протяжении всей статьи мы используем термин «фотография» взаимозаменяемо с изображением и видом, и все они относятся к обычному двухмерному изображению. Мы определяем коллекцию как набор фотографий. В своей основной форме краткое содержание из изображений (summary) представляет собой набор фотографий, представляющих наиболее интересный визуальный контент из коллекции изображений.'">Мы начнем с определения некоторой терминологии. На протяжении всей статьи мы используем термин «фотография» взаимозаменяемо с изображением и видом, и все они относятся к обычному двухмерному изображению. Мы определяем коллекцию как набор фотографий. В своей основной форме краткое содержание из изображений (summary) представляет собой набор фотографий, представляющих наиболее интересный визуальный контент из коллекции изображений.</p>

<p onmousedown="this.innerHTML='The purpose of a summary is to quickly give a viewer an accurate impression of what an image collection is trying to represent. Our goal, then, given a set of photos μ of a single image collection S, is to compute a summary C ⊆ μ such that most of the interesting visual content in μ is represented in C. This paper discusses the techniques we use for achieving this goal.'" onmouseout="this.innerHTML='Цель summary - быстро дать человеку точное представление о том, что пытается представить коллекция изображений. Таким образом, наша цель, имея набор фотографий μ из коллекции изображений S, состоит в том, чтобы вычислить итоговое значение C ⊆ μ так, чтобы большая часть интересного визуального содержимого в μ была представлена в C. В этой статье обсуждаются методы, которые мы используем для достижения этой цели.'">Цель summary - быстро дать человеку точное представление о том, что пытается представить коллекция изображений. Таким образом, наша цель, имея набор фотографий μ из коллекции изображений S, состоит в том, чтобы вычислить итоговое значение C ⊆ μ так, чтобы большая часть интересного визуального содержимого в μ была представлена в C. В этой статье обсуждаются методы, которые мы используем для достижения этой цели.</p>

<p onmousedown="this.innerHTML='First, Using the SIFT vectors we represent every image in the form of ’bag of words’ by clustering these SIFT vectors into several bins, thereby representing each image as a histogram of probability distribution of these vectors over these bins. We then use topic modelling technique of Latent Dirichlet Allocation [2] to partition the collection of photographs into clusters. The best image is identified by the image vector with the least within cluster sum of square distances from other image vectors of the cluster.
'" onmouseout="this.innerHTML='Во-первых, используя векторы SIFT, мы представляем каждое изображение в форме «мешка слов», группируя эти векторы SIFT в несколько корзин, тем самым представляя каждое изображение в виде гистограммы распределения вероятности этих векторов по этим корзинам. Затем мы используем метод тематического моделирования, латентное размещение  Дирихле [2], чтобы разбить коллекцию фотографий на кластеры. Лучшее изображение идентифицируется вектором изображения с наименьшей в пределах кластера суммой квадратных расстояний от других векторов изображения кластера.'">Во-первых, используя векторы SIFT, мы представляем каждое изображение в форме «мешка слов», группируя эти векторы SIFT в несколько корзин, тем самым представляя каждое изображение в виде гистограммы распределения вероятности этих векторов по этим корзинам. Затем мы используем метод тематического моделирования, латентное размещение  Дирихле [2], чтобы разбить коллекцию фотографий на кластеры. Лучшее изображение идентифицируется вектором изображения с наименьшей в пределах кластера суммой квадратных расстояний от других векторов изображения кластера.</p>

<p onmousedown="this.innerHTML='We validate our results by judging the quality of summaries produced both on personal and general image collections. We get the summaries rated both by people who are a part of the images and the ones not a part of them.'" onmouseout="this.innerHTML='Мы проверяем наши результаты, оценивая качество summary, созданных как на личных, так и на публичных коллекциях изображений. Мы получаем summary, оцениваемые как людьми, которые встречаются на изображениях, так и теми, которые не встречаются.'">Мы проверяем наши результаты, оценивая качество summary, созданных как на личных, так и на публичных коллекциях изображений. Мы получаем summary, оцениваемые как людьми, которые встречаются на изображениях, так и теми, которые не встречаются.</p>

<p onmousedown="this.innerHTML='We claim that an effective subset summary should satisfy some desirable properties. These properties are:'" onmouseout="this.innerHTML='Мы утверждаем, что эффективное саммари подмножества должно удовлетворять некоторым желательным свойствам, таким как:'">Мы утверждаем, что эффективное саммари подмножества должно удовлетворять некоторым желательным свойствам, таким как:</p>

<ul>
  <li onmousedown="this.innerHTML='QUALITY of a photo summary determines the aggregate interestingness or attractiveness of the photos present in it.'" onmouseout="this.innerHTML='КАЧЕСТВО суммаризации фотографий определяет совокупную интересность или привлекательность фотографий, представленных в ней.'">КАЧЕСТВО суммаризации фотографий определяет совокупную интересность или привлекательность фотографий, представленных в ней.</li>
  <li onmousedown="this.innerHTML='DIVERSITY of a summary is a measure of its nonredundancy.'" onmouseout="this.innerHTML='РАЗНООБРАЗИЕ суммаризации является мерой ее не избыточности.'">РАЗНООБРАЗИЕ суммаризации является мерой ее не избыточности.</li>
  <li onmousedown="this.innerHTML='COVERAGE ensures that the important concepts present in the image collection are also represented in the size constrained summary.'" onmouseout="this.innerHTML='ОХВАТ гарантирует, что важные понятия, представленные в коллекции изображений, также представлены в суммаризации.'">ОХВАТ гарантирует, что важные понятия, представленные в коллекции изображений, также представлены в суммаризации.</li>
</ul>

<p onmousedown="this.innerHTML='The raters are asked to rate the summaries on these 3 properties. The results for the same are presented in the results section.'" onmouseout="this.innerHTML='Оценщиков просили оценить суммаризацию по этим 3 свойствам. Полученные оценки представлены в разделе результатов.'">Оценщиков просили оценить суммаризацию по этим 3 свойствам. Полученные оценки представлены в разделе результатов.</p>


<p onmousedown="this.innerHTML='For partitioning of images we are not using timestamps[3] as they assume that similar images are clicked within a specified time interval. This assumption is often flawed and misleading and can lead to poor summarization and hence we avoid using the same to make any decisions. We also avoid the use of topic tags and geo-tags, as theeffectiveness of these is questionable. Instead we use SIFT feature vectors which are invariant to rotation, translation, scaling and partially invariant to illumination changes and affine or 3D projection which prove a good measure to identify similar images [4]. Using SIFT allows us to ignore rotation, illumination, scaling and other such effects and instead focus on the contents of the image. The exclusion of timestamp, topic tags and geo-tags and solely focusing on the image contents is one of the novelties in our paper. The use of topic modelling techniques, traditionally used for document classification to image summarization by representing images as documents is another major novelty in the approach we propose. This allows us to model the image contents in an efficient manner and use it for summarization. This is also what makes the approach scalable as the ultimate classification is not on the entire image but it’s representation as a document or more specifically as a histogram over topic probabilities and processing documents is much faster than directly applying classification algorithms on images. This effective processing allows for speedy implementation of the approach and allows us to process a large number of images in a feasible amount of time.'" onmouseout="this.innerHTML='Для разделения изображений мы не используем временные метки [3], поскольку тогда можно подумать, что похожие изображения были сняты в течение заданного интервала времени. Это предположение часто ошибочно и вводит в заблуждение и может привести к плохому обобщению, и, следовательно, мы избегаем использовать его для принятия каких-либо решений. Мы также избегаем использования тематических тегов и геотегов, поскольку их эффективность сомнительна. Вместо этого мы используем векторы признаков SIFT, которые инвариантны к вращению, перемещению, масштабированию и частично инвариантны к изменениям освещения и аффинной или трехмерной проекции, которые являются хорошей мерой для идентификации похожих изображений [4]. Использование SIFT позволяет нам игнорировать вращение, освещение, масштабирование и другие подобные эффекты и вместо этого сосредоточиться на содержании изображения. Исключение меток времени, тематических тегов и геотегов и исключительно сосредоточение внимания на содержании изображения - одна из новых идей, о которых мы рассказываем в нашей статье. Еще одной новой идеей является то, что мы используем тематическое моделирование, которое обычно используется для текстов, для суммаризации изображений путем представления изображений в виде документов. Это позволяет нам эффективно моделировать содержимое изображения и использовать его для суммаризации. Это также делает наш подход масштабируемым, поскольку окончательная классификация относится не ко всему изображению, а к его представлению в виде документа или, более конкретно, в виде гистограммы по вероятностям темы, и обработка документов выполняется намного быстрее, чем непосредственное применение алгоритмов классификации к изображениям. Эта эффективная обработка позволяет быстро реализовать подход и позволяет обрабатывать большое количество изображений за приемлемое количество времени.'">Для разделения изображений мы не используем временные метки [3], поскольку тогда можно подумать, что похожие изображения были сняты в течение заданного интервала времени. Это предположение часто ошибочно и вводит в заблуждение и может привести к плохому обобщению, и, следовательно, мы избегаем использовать его для принятия каких-либо решений. Мы также избегаем использования тематических тегов и геотегов, поскольку их эффективность сомнительна. Вместо этого мы используем векторы признаков SIFT, которые инвариантны к вращению, перемещению, масштабированию и частично инвариантны к изменениям освещения и аффинной или трехмерной проекции, которые являются хорошей мерой для идентификации похожих изображений [4]. Использование SIFT позволяет нам игнорировать вращение, освещение, масштабирование и другие подобные эффекты и вместо этого сосредоточиться на содержании изображения. Исключение меток времени, тематических тегов и геотегов и исключительно сосредоточение внимания на содержании изображения - одна из новых идей, о которых мы рассказываем в нашей статье. Еще одной новой идеей является то, что мы используем тематическое моделирование, которое обычно используется для текстов, для суммаризации изображений путем представления изображений в виде документов. Это позволяет нам эффективно моделировать содержимое изображения и использовать его для суммаризации. Это также делает наш подход масштабируемым, поскольку окончательная классификация относится не ко всему изображению, а к его представлению в виде документа или, более конкретно, в виде гистограммы по вероятностям темы, и обработка документов выполняется намного быстрее, чем непосредственное применение алгоритмов классификации к изображениям. Эта эффективная обработка позволяет быстро реализовать подход и позволяет обрабатывать большое количество изображений за приемлемое количество времени.</p>

<p onmousedown="this.innerHTML='The remainder of the paper is organized as follows: Literature Review is presented in section 2. Proposed algorithm for image summarization of a collection of photographs is explained in section 3. In section 4, experimental setup is mentioned along with results and discussions followed by section 5 which presents the conclusions of the paper. Finally section 6 discussed our future intentions and the work we plan to do to extend this project.'" onmouseout="this.innerHTML='Остальная часть статьи организована следующим образом: Обзор литературы представлен в разделе 2. Предлагаемый алгоритм суммаризации изображений коллекции фотографий объясняется в разделе 3. В разделе 4 упоминается экспериментальная установка, а также результаты и обсуждения, за которыми следует раздел 5, в котором представлены выводы по статье. Наконец, в разделе 6 обсуждались наши будущие намерения и работа, которую мы планируем сделать для расширения этого проекта.'">Остальная часть статьи организована следующим образом: Обзор литературы представлен в разделе 2. Предлагаемый алгоритм суммаризации изображений коллекции фотографий объясняется в разделе 3. В разделе 4 упоминается экспериментальная установка, а также результаты и обсуждения, за которыми следует раздел 5, в котором представлены выводы по статье. Наконец, в разделе 6 обсуждались наши будущие намерения и работа, которую мы планируем сделать для расширения этого проекта.</p>

# Обзор литературы

<p onmousedown="this.innerHTML='The task of summarizing a collection of photographs can be broadly divided into two parts namely clustering the given images and choosing the best image from the cluster. Most photo clustering techniques that have been used previously employ timestamps and content of the photo as the partitioning criteria. In 2003, Toyama [5] proposed an application built on top of the World Wide Media eXchange (WWMX) providing auto clustering functions according to geographic location tags. GPS information is also a very useful clustering criterion however current digital cameras with GPS system are not widely distributed, and hence it can’t be expected to always have geo-tagged images.'" onmouseout="this.innerHTML='Задача суммаризации коллекции фотографий может быть разделена на две части: кластеризация изображений и выбор лучшего изображения из кластера. Большинство методов кластеризации фотографий, которые использовались ранее, используют метки времени и содержание фотографии в качестве критериев разделения. В 2003 году Тояма [5] предложил приложение, созданное поверх World Wide Media eXchange (WWMX), обеспечивающее функции автоматической кластеризации в соответствии с тегами географического местоположения. Информация GPS также является очень полезным критерием кластеризации, однако современные цифровые камеры с системой GPS не имеют широкого распространения, и, следовательно, нельзя ожидать, что у них всегда будут геотегированные изображения.'">Задача суммаризации коллекции фотографий может быть разделена на две части: кластеризация изображений и выбор лучшего изображения из кластера. Большинство методов кластеризации фотографий, которые использовались ранее, используют метки времени и содержание фотографии в качестве критериев разделения. В 2003 году Тояма [5] предложил приложение, созданное поверх World Wide Media eXchange (WWMX), обеспечивающее функции автоматической кластеризации в соответствии с тегами географического местоположения. Информация GPS также является очень полезным критерием кластеризации, однако современные цифровые камеры с системой GPS не имеют широкого распространения, и, следовательно, нельзя ожидать, что у них всегда будут геотегированные изображения.</p>

<p onmousedown="this.innerHTML='Yang and Wang in 2009 [6] used ’bag-of-words’ visual model for grouping scene images. This model has the role of giving similarity between images which is used to divide a large image collection into coarser groups. They quantize SIFT feature vectors using the Greed N-Best Paths (GNP) algorithm and further used area-ratio constraint to match the features between each pair of images. AutoAlbum [7] used time and photo creation order to make a temporally contiguous photo group. To provide the contiguous photo group they employ the best-first probabilistic model merging algorithm.'" onmouseout="this.innerHTML='Ян и Ван в 2009 году [6] использовали визуальную модель «мешка слов» для группировки изображений сцены. Эта модель играет роль обеспечения сходства между изображениями, которое используется для разделения большой коллекции изображений на более грубые группы. Они квантуют векторы признаков SIFT, используя алгоритм Greed N-Best Paths (GNP), и дополнительно используют ограничение соотношения площадей для сопоставления характеристик между каждой парой изображений. AutoAlbum [7] использовал порядок создания времени и фотографий для создания непрерывной во времени фотогруппы. Чтобы создать непрерывную фотогруппу, они используют алгоритм слияния наилучшей первой вероятностной модели.'">Ян и Ван в 2009 году [6] использовали визуальную модель «мешка слов» для группировки изображений сцены. Эта модель играет роль обеспечения сходства между изображениями, которое используется для разделения большой коллекции изображений на более грубые группы. Они квантуют векторы признаков SIFT, используя алгоритм Greed N-Best Paths (GNP), и дополнительно используют ограничение соотношения площадей для сопоставления характеристик между каждой парой изображений. AutoAlbum [7] использовал порядок создания времени и фотографий для создания непрерывной во времени фотогруппы. Чтобы создать непрерывную фотогруппу, они используют алгоритм слияния наилучшей первой вероятностной модели.</p>

<p onmousedown="this.innerHTML='Cooper in 2005 [8] found temporal similarity between images using logistic function using time intervals. He also visualized his clustering result using a DCT matrix.'" onmouseout="this.innerHTML='Купер в 2005 году [8] обнаружил временное сходство между изображениями с помощью логистической функции с использованием временных интервалов. Он также визуализировал свой результат кластеризации, используя матрицу DCT.'">Купер в 2005 году [8] обнаружил временное сходство между изображениями с помощью логистической функции с использованием временных интервалов. Он также визуализировал свой результат кластеризации, используя матрицу DCT.</p>

<p onmousedown="this.innerHTML='Graham [9] proposed Calendar Browser and Hierarchical Browser to exploit the timing information. He considers photo shoot times and semantically related photos tend to occur together when he constructs hierarchical photo structure. Boutell [10] in 2005 proposed a general probabilistic temporal context model which used the first-order Markov property and is used to integrate content-based and temporal context cues. Chum and Matas in 2009 [11] used the min-Hash algorithm to find out the cluster seeds and then the seeds are used as the visual queries to obtain the clusters.'" onmouseout="this.innerHTML='Грэм [9] предложил использовать браузер календаря и иерархический браузер, чтобы использовать информацию о времени. Он учитывает время фотосессии, и семантически связанные фотографии имеют тенденцию происходить вместе, когда он строит иерархическую структуру фотографии. В 2005 году Бутелл [10] предложил общую вероятностную модель временного контекста, которая использовала свойство Маркова первого порядка и использовалась для интеграции контентных и временных контекстных сигналов. Чум и Мэйтас в 2009 году [11] использовали алгоритм min-Hash, чтобы выяснить начальные числа кластеров, а затем их используют в качестве визуальных запросов для получения кластеров.'">Грэм [9] предложил использовать браузер календаря и иерархический браузер, чтобы использовать информацию о времени. Он учитывает время фотосессии, и семантически связанные фотографии имеют тенденцию происходить вместе, когда он строит иерархическую структуру фотографии. В 2005 году Бутелл [10] предложил общую вероятностную модель временного контекста, которая использовала свойство Маркова первого порядка и использовалась для интеграции контентных и временных контекстных сигналов. Чум и Мэйтас в 2009 году [11] использовали алгоритм min-Hash, чтобы выяснить начальные числа кластеров, а затем их используют в качестве визуальных запросов для получения кластеров.</p>

<p onmousedown="this.innerHTML='In 2008, Jang [12] proposed a clustering algorithm for concurrent digital photos obtained for multiple cameras. A colour based block matching is used to consider the content based similarity. In 2011, Ryu et al. [13] proposed a queue-based hierarchical clustering method using photo timestamps. They used recursive partitioning called by a priority queue enabling classified photo groups with maximum variance to be primarily selected.'" onmouseout="this.innerHTML='В 2008 году Янг [12] предложил алгоритм кластеризации для одновременных цифровых фотографий, полученных для нескольких камер. Сопоставление блоков на основе цвета используется для учета сходства на основе содержимого. В 2011 году Рю и соавт. [13] предложили метод иерархической кластеризации на основе очередей с использованием временных меток фотографий. Они использовали рекурсивное разбиение, вызываемое приоритетной очередью, позволяя в первую очередь выбирать классифицированные фотогруппы с максимальной дисперсией.'">В 2008 году Янг [12] предложил алгоритм кластеризации для одновременных цифровых фотографий, полученных для нескольких камер. Сопоставление блоков на основе цвета используется для учета сходства на основе содержимого. В 2011 году Рю и соавт. [13] предложили метод иерархической кластеризации на основе очередей с использованием временных меток фотографий. Они использовали рекурсивное разбиение, вызываемое приоритетной очередью, позволяя в первую очередь выбирать классифицированные фотогруппы с максимальной дисперсией.</p>

<p onmousedown="this.innerHTML='In 2007 Simon et al. [14] attempted to do a scene summarization of an image collection by using clustering techniques and trying to decompose an image into ’canonical views’ or views of interest. They also used timestamps and user tags for this task. Furthermore, they proposed a greedy algorithm to optimize their objective. A similar approach was proposed by Sinha et al. in papers [15] and [16], where a set cover function is used to model coverage, and a minimum disparity formulation is used to model diversity. They too optimize their objective using the same greedy algorithm.'" onmouseout="this.innerHTML='В 2007 году Саймон и соавт. [14] попытались выполнить суммаризацию коллекции изображений, используя методы кластеризации и раскладывая изображение на «канонические виды» или представления, представляющие интерес. Они также использовали метки времени и пользовательские теги для этой задачи. Кроме того, они предложили жадный алгоритм для оптимизации своей цели. Аналогичный подход был предложен Sinha et al. в работах [15] и [16], где в качестве модели покрытия используется функция покрытия множества, а для моделирования разнообразия используется формула минимального диспаратности. Они тоже оптимизируют свою цель, используя тот же жадный алгоритм.'">В 2007 году Саймон и соавт. [14] попытались выполнить суммаризацию коллекции изображений, используя методы кластеризации и раскладывая изображение на «канонические виды» или представления, представляющие интерес. Они также использовали метки времени и пользовательские теги для этой задачи. Кроме того, они предложили жадный алгоритм для оптимизации своей цели. Аналогичный подход был предложен Sinha et al. в работах [15] и [16], где в качестве модели покрытия используется функция покрытия множества, а для моделирования разнообразия используется формула минимального диспаратности. Они тоже оптимизируют свою цель, используя тот же жадный алгоритм.</p>

<p onmousedown="this.innerHTML='Denton et al. [17] use a semidefinite programming relaxation to select canonical views from a larger set of views, choosing views which are as similar as possible to the non-canonical views while being dissimilar to each other.'" onmouseout="this.innerHTML='Дентон и соавт. [17] используют полуопределенную программную релаксацию для выбора канонических видов из большего набора видов, выбирая виды, которые максимально похожи на неканонические, но не похожи друг на друга.'">Дентон и соавт. [17] используют полуопределенную программную релаксацию для выбора канонических видов из большего набора видов, выбирая виды, которые максимально похожи на неканонические, но не похожи друг на друга.</p>

<p onmousedown="this.innerHTML='Rother et al. [18] stitch together salient and spatially compatible blocks from the input image set to summarize the set of images with a ”digital tapestry”. Wang et al. [19] create a ”picture collage”, a 2D spatial arrangement of the images in the input set chosen to maximize the visibility of salient regions. Both these works try to determine the visual layout after already haven chosen the set of images to appear. We ignore issues of layout and focus on selecting the set of images to appear in the summary.'" onmouseout="this.innerHTML='Ротер и соавт. [18] сшивают вместе значимые и пространственно совместимые блоки из набора входных изображений, чтобы суммаризировать набор изображений с помощью «цифрового гобелена». Ван и соавт. [19] создавали «коллаж изображения»: 2D пространственное расположение изображений во входном наборе, выбранном для максимизации видимости выделенных областей. Обе эти работы пытаются определить визуальный макет после того, как уже выбрали набор изображений для отображения. Мы игнорируем вопросы макета и фокусируемся на выборе набора изображений для отображения в сводке.'">Ротер и соавт. [18] сшивают вместе значимые и пространственно совместимые блоки из набора входных изображений, чтобы суммаризировать набор изображений с помощью «цифрового гобелена». Ван и соавт. [19] создавали «коллаж изображения»: 2D пространственное расположение изображений во входном наборе, выбранном для максимизации видимости выделенных областей. Обе эти работы пытаются определить визуальный макет после того, как уже выбрали набор изображений для отображения. Мы игнорируем вопросы макета и фокусируемся на выборе набора изображений для отображения в сводке.</p>

<p onmousedown="this.innerHTML='Kim et al. [20] try to create image summaries as storyline graphs by using sparse time-varying directed graphs. They also perform video summarization, which is achieved by diversity ranking on the similarity graphs between images and video frames.'" onmouseout="this.innerHTML=''"></p>

<p onmousedown="this.innerHTML='Tschiatschek et al. [21] address the problem of image collection summarization by learning mixtures of submodular functions. They provide classes of submodular component functions (including some which are instantiated via a deep neural network) over which mixtures may be learnt. They formulate the learning of such mixtures as a supervised problem via large-margin structured prediction.'" onmouseout="this.innerHTML='Tschiatschek et al. [21] решают проблему суммаризации коллекции изображений, изучая смеси субмодульных функций. Они предоставляют классы субмодульных компонентных функций (включая те, которые создаются с помощью глубокой нейронной сети), по которым могут изучаться смеси. Они формулируют изучение таких смесей как контролируемую проблему посредством структурированного прогнозирования с большим зазором.'">Tschiatschek et al. [21] решают проблему суммаризации коллекции изображений, изучая смеси субмодульных функций. Они предоставляют классы субмодульных компонентных функций (включая те, которые создаются с помощью глубокой нейронной сети), по которым могут изучаться смеси. Они формулируют изучение таких смесей как контролируемую проблему посредством структурированного прогнозирования с большим зазором.</p>

<p onmousedown="this.innerHTML='Image tags and geo-tags have often been used in the past for the summarization task. For example Jaffe et al. [22] summarize a set of images using only tags and geotags. They try to correlate tags and geo-tags and try to overlay these images over a geographical map. Schmitz [23] relies on Flickr tags, which are typically noisier and less informative than the content of the images and are often non-existent. All of these approaches could be used to further organize our summaries. However, none of them take advantage of the visual information in the images to fill in for bad or missing metadata.'" onmouseout="this.innerHTML='Теги изображений и геотеги часто использовались в прошлом для задачи суммаризации. Например, Jaffe et al. [22] суммаризировали набор изображений, используя только теги и геотеги. Они пытались соотнести теги и геотеги и пытались наложить эти изображения на географическую карту. Schmitz [23] опирается на теги Flickr, которые, как правило, более шумные и менее информативные, чем содержание изображений, и зачастую отсутствуют. Все эти подходы могут быть использованы для дальнейшей организации наших суммаризаций. Тем не менее, ни один из них не использует визуальную информацию на изображениях, чтобы заполнить недостающие или отсутствующие метаданные.'">Теги изображений и геотеги часто использовались в прошлом для задачи суммаризации. Например, Jaffe et al. [22] суммаризировали набор изображений, используя только теги и геотеги. Они пытались соотнести теги и геотеги и пытались наложить эти изображения на географическую карту. Schmitz [23] опирается на теги Flickr, которые, как правило, более шумные и менее информативные, чем содержание изображений, и зачастую отсутствуют. Все эти подходы могут быть использованы для дальнейшей организации наших суммаризаций. Тем не менее, ни один из них не использует визуальную информацию на изображениях, чтобы заполнить недостающие или отсутствующие метаданные.</p>

# Тематическое моделирование с использованием SIFT векторов и тематического моделирования

<p onmousedown="this.innerHTML='Our proposed approach can be broadly classified into four categories. The approach is clearly explained by the means of a flowchart in Fig. 2. First we represent the images by applying SIFT on the images and representing the SIFT feature vectors in the 1024 dimensional space. The feature extraction technique is clearly explained by the means of the flowchart in Fig. 3. In the second step these image vectors are quantized into bins to create a probability histogram which is used to represent an image. In the third step, we apply LDA on these probability histograms to ultimately cluster images based on probability distribution over underlying set of topics identified by LDA. LDA assumes a generative probabilistic model on text documents and their underlying topics. Given a pre-defined number of topics, k, LDA models each topic as a probability distribution over words. Just as each topic is modeled as a probability distribution over words, each document is modeled as a probability distribution over topics. This probability distribution over topics is what is used to cluster images. Finally, after having clustered the images we choose a fixed number of images from each cluster as the representative of that cluster and ensure that the best images are chosen from each cluster. Picking a fixed number of images per cluster ensures that we choose a representative summary, that is all different kinds of images find representation in the image summary. The four steps are further explained in the sections to follow.'" onmouseout="this.innerHTML='Предлагаемый нами подход можно в целом разделить на четыре категории. Подход четко объясняется с помощью блок-схемы последовательности операций на рис. 2. Сначала мы представляем изображения, применяя SIFT к изображениям и представляя векторы признаков SIFT в 1024-мерном пространстве. Техника выделения признаков четко поясняется с помощью блок-схемы последовательности операций на рис. 3. На втором этапе эти векторы изображения квантуются в ячейки для создания гистограммы вероятности, которая используется для представления изображения. На третьем этапе мы применяем LDA к этим гистограммам вероятности, чтобы в конечном итоге кластеризовать изображения на основе распределения вероятностей по базовому набору тем, определенных LDA. LDA предполагает генеративную вероятностную модель текстовых документов и их основных тем. Учитывая заранее определенное количество тем, k, LDA моделирует каждую тему как распределение вероятностей по словам. Подобно тому, как каждая тема моделируется как распределение вероятностей по словам, каждый документ моделируется как распределение вероятностей по темам. Такое распределение вероятностей по темам используется для кластеризации изображений. Наконец, после кластеризации изображений мы выбираем фиксированное количество изображений из каждого кластера в качестве представителя этого кластера и гарантируем, что из каждого кластера выбраны лучшие изображения. Выбор фиксированного количества изображений на кластер гарантирует, что мы выберем репрезентативную сводку, то есть все различные виды изображений найдут представление в сводке изображений. Четыре шага более подробно описаны в следующих разделах.'">Предлагаемый нами подход можно в целом разделить на четыре категории. Подход четко объясняется с помощью блок-схемы последовательности операций на рис. 2. Сначала мы представляем изображения, применяя SIFT к изображениям и представляя векторы признаков SIFT в 1024-мерном пространстве. Техника выделения признаков четко поясняется с помощью блок-схемы последовательности операций на рис. 3. На втором этапе эти векторы изображения квантуются в ячейки для создания гистограммы вероятности, которая используется для представления изображения. На третьем этапе мы применяем LDA к этим гистограммам вероятности, чтобы в конечном итоге кластеризовать изображения на основе распределения вероятностей по базовому набору тем, определенных LDA. LDA предполагает генеративную вероятностную модель текстовых документов и их основных тем. Учитывая заранее определенное количество тем, k, LDA моделирует каждую тему как распределение вероятностей по словам. Подобно тому, как каждая тема моделируется как распределение вероятностей по словам, каждый документ моделируется как распределение вероятностей по темам. Такое распределение вероятностей по темам используется для кластеризации изображений. Наконец, после кластеризации изображений мы выбираем фиксированное количество изображений из каждого кластера в качестве представителя этого кластера и гарантируем, что из каждого кластера выбраны лучшие изображения. Выбор фиксированного количества изображений на кластер гарантирует, что мы выберем репрезентативную сводку, то есть все различные виды изображений найдут представление в сводке изображений. Четыре шага более подробно описаны в следующих разделах.</p>

<center><img src="{{ site.img_path }}/summary_w_topic_modeling/top_view_idea.png" width="60%"></center>

<center>Рис. 2 Подход предложенный нами</center>

<center><img src="{{ site.img_path }}/summary_w_topic_modeling/feature_extraction_flow.png" width="60%"></center>

<center>Рис. 3 Последовательность вытаскивания фичей</center>

## Вытаскивание фичей

<p onmousedown="this.innerHTML='Previous research in the field of image summarization has been focused more on partitioning images based on timestamps rather than the content of photograph. Timestamps are considered inefficient measure to cluster images as they can be manually turned off for a camera and instances in which a user visits a place daily/weekly could fail to put images of the same place to the same cluster. Taking into consideration all these factors we have ignored timestamps in our research and instead rely on the image content for summarization.'" onmouseout="this.innerHTML='Предыдущие исследования в области суммаризации изображений были сосредоточены больше на разделении изображений на основе временных отметок, а не на содержании фотографии. Временные метки считаются неэффективной мерой для кластеризации изображений, так как они могут быть отключены вручную для камеры, и в случаях, когда пользователь посещает место ежедневно / еженедельно, может быть невозможно поместить изображения одного и того же места в один кластер. Принимая во внимание все эти факторы, мы игнорировали временные метки в наших исследованиях и вместо этого полагаемся на содержание изображения для суммаризации.'">Предыдущие исследования в области суммаризации изображений были сосредоточены больше на разделении изображений на основе временных отметок, а не на содержании фотографии. Временные метки считаются неэффективной мерой для кластеризации изображений, так как они могут быть отключены вручную для камеры, и в случаях, когда пользователь посещает место ежедневно / еженедельно, может быть невозможно поместить изображения одного и того же места в один кластер. Принимая во внимание все эти факторы, мы игнорировали временные метки в наших исследованиях и вместо этого полагаемся на содержание изображения для суммаризации.</p>

<p onmousedown="this.innerHTML='We use Scale Invariant Feature Transform for feature extraction and use the obtained SIFT feature vectors as the representative of an image. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images [24]. The parameters to SIFT algorithm are chosen in a way to fix the number of features points extracted per image to 1024. This allows us to represent each image as a point in the 1024 dimensional space. Following are the major stages of computation used to generate the set of image features:'" onmouseout="this.innerHTML='Мы используем Scale Invariant Feature Transform для извлечения объектов и используем полученные векторы SIFT-объектов в качестве представителя изображения. Эти признаки не зависят от масштаба и поворота изображения и, как показано, обеспечивают надежное согласование в широком диапазоне аффинных искажений, изменение 3D-точки обзора, добавление шума и изменение освещенности. Эти признаки являются весьма отличительными, в том смысле, что один объект может быть с высокой вероятностью правильно сопоставлен с большой базой данных из множества изображений [24]. Параметры алгоритма SIFT выбираются таким образом, чтобы фиксировать число признаков, изображения до 1024. Это позволяет нам представлять каждое изображение как точку в 1024-мерном пространстве. Ниже приведены основные этапы вычислений, используемые для создания набора признаков изображения:'">Мы используем Scale Invariant Feature Transform для извлечения объектов и используем полученные векторы SIFT-объектов в качестве представителя изображения. Эти признаки не зависят от масштаба и поворота изображения и, как показано, обеспечивают надежное согласование в широком диапазоне аффинных искажений, изменение 3D-точки обзора, добавление шума и изменение освещенности. Эти признаки являются весьма отличительными, в том смысле, что один объект может быть с высокой вероятностью правильно сопоставлен с большой базой данных из множества изображений [24]. Параметры алгоритма SIFT выбираются таким образом, чтобы фиксировать число признаков, изображения до 1024. Это позволяет нам представлять каждое изображение как точку в 1024-мерном пространстве. Ниже приведены основные этапы вычислений, используемые для создания набора признаков изображения:</p>

<ul>
  <li onmousedown="this.innerHTML='<b>Scale-space extrema detection</b> : The first stage of computation searches over all scales and image locations. It is implemented efficiently by using a difference-of-Gaussian function to identify potential interest points that are invariant to scale and orientation.'" onmouseout="this.innerHTML='<b> Обнаружение экстремумов в масштабе шкалы </b>. На первом этапе вычислений выполняется поиск по всем масштабам и местоположениям изображений. Он реализован эффективно с помощью функции разности гауссовских координат для определения потенциальных точек интереса, которые не зависят от масштаба и ориентации.'"><b> Обнаружение экстремумов в масштабе шкалы </b>. На первом этапе вычислений выполняется поиск по всем масштабам и местоположениям изображений. Он реализован эффективно с помощью функции разности гауссовских координат для определения потенциальных точек интереса, которые не зависят от масштаба и ориентации.</li>
  <li onmousedown="this.innerHTML='<b>Keypoint localization</b> : At each candidate location, a detailed model is fit to determine location and scale. Keypoints are selected based on measures of their stability.'" onmouseout="this.innerHTML='<b> Локализация ключевых точек </b>. Для каждого предполагаемого местоположения подбирается детальная модель для определения местоположения и масштаба. Ключевые точки выбираются исходя из показателей их устойчивости.'"><b> Локализация ключевых точек </b>. Для каждого предполагаемого местоположения подбирается детальная модель для определения местоположения и масштаба. Ключевые точки выбираются исходя из показателей их устойчивости.</li>
  <li onmousedown="this.innerHTML='<b>Orientation assignment</b> : One or more orientations are assigned to each keypoint location based on local image gradient directions. All future operations are performed on image data that has been transformed relative to the assigned orientation, scale, and location for each feature, thereby providing invariance to these transformations.'" onmouseout="this.innerHTML='<b>Назначение ориентации</b> Одна или несколько ориентаций назначаются каждой ключевой точке на основании локальных направлений градиента изображения. Все будущие операции выполняются с данными изображения, которые были преобразованы относительно назначенной ориентации, масштаба и местоположения для каждой функции, тем самым обеспечивая неизменность этих преобразований.'"><b>Назначение ориентации</b> Одна или несколько ориентаций назначаются каждой ключевой точке на основании локальных направлений градиента изображения. Все будущие операции выполняются с данными изображения, которые были преобразованы относительно назначенной ориентации, масштаба и местоположения для каждой функции, тем самым обеспечивая неизменность этих преобразований.</li>
  <li onmousedown="this.innerHTML='<b>Keypoint descriptor</b> : The local image gradients are measured at the selected scale in the region around each keypoint. These are transformed into a representation that allows for significant levels of local shape distortion and change in illumination.'" onmouseout="this.innerHTML='<b>Описание ключевых точек</b> : Локальные градиенты изображения измеряются в выбранном масштабе в области вокруг каждой ключевой точки. Они преобразуются в представление, которое учитывает значительные уровни локальных искажений формы и изменения освещенности.'"><b>Описание ключевых точек</b>: Локальные градиенты изображения измеряются в выбранном масштабе в области вокруг каждой ключевой точки. Они преобразуются в представление, которое учитывает значительные уровни локальных искажений формы и изменения освещенности.</li>
</ul>

## Квантирование векторов-признаков SIFT

<p onmousedown="this.innerHTML='Image matching involves distance computations across all pairs of SIFT feature vectors from both images, which is quite costly. In 2011 Peker [25] shows that SIFT features perform well even after quantization. Hence we quantize the SIFT feature vectors by assigning them to distinct bins. This allows us to represent the images as a histogram of probability distribution over these bins.'" onmouseout="this.innerHTML='Сопоставление изображений включает в себя вычисления расстояний по всем парам векторов признаков SIFT из обоих изображений, что является довольно дорогостоящим. В 2011 году Пекер [25] показывает, что функции SIFT работают хорошо даже после квантования. Следовательно, мы квантуем векторы признаков SIFT, назначая их различным ячейкам. Это позволяет нам представлять изображения в виде гистограммы распределения вероятностей по этим ячейкам.'">Сопоставление изображений включает в себя вычисления расстояний по всем парам векторов признаков SIFT из обоих изображений, что является довольно дорогостоящим. В 2011 году Пекер [25] показывает, что функции SIFT работают хорошо даже после квантования. Следовательно, мы квантуем векторы признаков SIFT, назначая их различным ячейкам. Это позволяет нам представлять изображения в виде гистограммы распределения вероятностей по этим ячейкам.</p>

<p onmousedown="this.innerHTML='First we accumulate all feature vectors and after applying SIFT we represent them in a 1024-dimensional space. We use k-means clustering approach to quantize thousands of SIFT feature vectors across 200 bins as shown in Fig. 1. Here each bin represents a ’word’. To derive the ’bag of words’ representation of any image, these bins are used to compose a histogram from the number of SIFT vectors belonging to each bin. This histogram is a ’bag of words’ vector.'" onmouseout="this.innerHTML='Сначала мы накапливаем все векторы признаков после применения SIFT представляем их в 1024-мерном пространстве. Для кластеризации мы используем метод k-means для квантования тысяч векторов признаков SIFT в 200 корзин, как показано на рисунке 1. Здесь каждая корзина представляет собой «слово». Чтобы получить представление «мешка слов» любого изображения, эти ячейки используются для составления гистограммы из числа векторов SIFT, принадлежащих каждому ячейке. Эта гистограмма является вектором «мешка слов».'">Сначала мы накапливаем все векторы признаков после применения SIFT представляем их в 1024-мерном пространстве. Для кластеризации мы используем метод k-means для квантования тысяч векторов признаков SIFT в 200 корзин, как показано на рисунке 1. Здесь каждая корзина представляет собой «слово». Чтобы получить представление «мешка слов» любого изображения, эти ячейки используются для составления гистограммы из числа векторов SIFT, принадлежащих каждому ячейке. Эта гистограмма является вектором «мешка слов».</p>

<center><img src="{{ site.img_path }}/summary_w_topic_modeling/clustering_of_image_vectors_into_bins.png" width="60%"></center>

<center>Рис. 1 Кластеризация векторов изображений</center>

<p onmousedown="this.innerHTML='Hence now our problem of image summarization has been reduced to document summarization and effective document classification and topic modelling techniques can now be used to achieve our goal. The effectiveness of these algorithms makes our model perform well in a computationally efficient manner even on large datasets.'" onmouseout="this.innerHTML='Таким образом, теперь наша проблема суммаризации изображений сводится к суммаризации документов, и для достижения нашей цели могут использоваться эффективные методы классификации документов и тематического моделирования. Качество этих алгоритмов делает нашу модель вычислительно эффективной даже на больших наборах данных.'">Таким образом, теперь наша проблема суммаризации изображений сводится к суммаризации документов, и для достижения нашей цели могут использоваться эффективные методы классификации документов и тематического моделирования. Качество этих алгоритмов делает нашу модель вычислительно эффективной даже на больших наборах данных.</p>

## Кластеризация изображений с помощью латентного размещения Дирихле

<p onmousedown="this.innerHTML='Having converted our images to documents the task of comparing images reduces comparison of the documents representing the images. To achieve this we use Latent Dirichlet Allocation, a generative probabilistic model, which models the documents as an infinite mixture of underlying set of topic probabilities [2]. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. The topic probabilities provide an explicit representation of a document which we utilize for the purpose of assigning images to clusters. Each topic represented by LDA is considered a cluster. We say that an image belongs to a particular cluster, if the probability of belonging to that cluster is greater than 80% of the maximum probability of belonging to any cluster. We consider clusters with top 4 probabilities for this process. This step is explained for an image in the Fig. 4. We choose the number of clusters to ensure that the total number of images in the summary, chosen from the clusters is same as the users’ target number of images. Lee et al. [26] propose an Interactive Visual Document Clustering technique via Topic modelling. They attempt to use various topic modelling techniques to cluster documents based on their similarities. Xie and Xing [27] also attempt to integrate the processes of document classification and topic modelling. They propose a multi- grain clustering topic model (MGCTM) which integrates document clustering and topic modelling into a unified framework and jointly performs the two tasks.'" onmouseout="this.innerHTML='Преобразовав наши изображения в документы, задача сравнения изображений уменьшает сравнение документов, представляющих изображения. Чтобы достичь этого, мы используем латентное размещение Дирихле, генеративную вероятностную модель, которая моделирует документы как бесконечную смесь базового набора тематических вероятностей [2]. Каждая тема, в свою очередь, смоделирована как бесконечная смесь по основному набору вероятностей темы. Тематические вероятности обеспечивают явное представление документа, который мы используем для назначения изображений кластерам. Каждая тема, представленная LDA, считается кластером. Мы говорим, что изображение принадлежит конкретному кластеру, если вероятность принадлежности к этому кластеру превышает 80% максимальной вероятности принадлежности к любому кластеру. Мы рассматриваем кластеры с 4 максимальными вероятностями для этого процесса. Этот шаг поясняется для изображения на рис. 4. Мы выбираем количество кластеров, чтобы убедиться, что общее количество изображений в суммаризации, выбранной из кластеров, совпадает с целевым числом изображений пользователей. Ли и соавт. [26] предлагают метод кластеризации интерактивных визуальных документов посредством моделирования тем. Они пытаются использовать различные методы моделирования тем для кластеризации документов на основе их сходства. Се и Син [27] также пытаются интегрировать процессы классификации документов и тематического моделирования. Они предлагают тематическую модель многоузловой кластеризации (MGCTM), которая объединяет кластеризацию документов и тематическое моделирование в единую структуру, которая совместно выполняет две задачи.'">Преобразовав наши изображения в документы, задача сравнения изображений уменьшает сравнение документов, представляющих изображения. Чтобы достичь этого, мы используем латентное размещение Дирихле, генеративную вероятностную модель, которая моделирует документы как бесконечную смесь базового набора тематических вероятностей [2]. Каждая тема, в свою очередь, смоделирована как бесконечная смесь по основному набору вероятностей темы. Тематические вероятности обеспечивают явное представление документа, который мы используем для назначения изображений кластерам. Каждая тема, представленная LDA, считается кластером. Мы говорим, что изображение принадлежит конкретному кластеру, если вероятность принадлежности к этому кластеру превышает 80% максимальной вероятности принадлежности к любому кластеру. Мы рассматриваем кластеры с 4 максимальными вероятностями для этого процесса. Этот шаг поясняется для изображения на рис. 4. Мы выбираем количество кластеров, чтобы убедиться, что общее количество изображений в суммаризации, выбранной из кластеров, совпадает с целевым числом изображений пользователей. Ли и соавт. [26] предлагают метод кластеризации интерактивных визуальных документов посредством моделирования тем. Они пытаются использовать различные методы моделирования тем для кластеризации документов на основе их сходства. Се и Син [27] также пытаются интегрировать процессы классификации документов и тематического моделирования. Они предлагают тематическую модель многоузловой кластеризации (MGCTM), которая объединяет кластеризацию документов и тематическое моделирование в единую структуру, которая совместно выполняет две задачи.</p>

<p onmousedown="this.innerHTML='We also experimented with Exponential-Family Approximation of the Dirichlet Compound Multinomial Distribution, an approach used by Elkan [28] for document clustering and classification. The Dirichlet compound multinomial (DCM) distribution, also called the multivariate Polya distribution, is a model for text documents that takes into account burstiness: the fact that if a word occurs once in a document, it is likely to occur repeatedly.'" onmouseout="this.innerHTML='Мы также экспериментировали с приближением экспоненциального семейства мультиномиального распределения соединений Дирихле, подходом, использованным Элканом [28] для кластеризации и классификации документов. Распределение составных многочленов (DCM) Дирихле, также называемое многомерным распределением Полиа, представляет собой модель для текстовых документов, которая учитывает всплески: тот факт, что если слово встречается в документе один раз, оно, вероятно, встречается неоднократно.'">Мы также экспериментировали с приближением экспоненциального семейства мультиномиального распределения соединений Дирихле, подходом, использованным Элканом [28] для кластеризации и классификации документов. Распределение составных многочленов (DCM) Дирихле, также называемое многомерным распределением Полиа, представляет собой модель для текстовых документов, которая учитывает всплески: тот факт, что если слово встречается в документе один раз, оно, вероятно, встречается неоднократно.</p>

<p onmousedown="this.innerHTML='However the approach didn’t perform as well as the LDA based approach and hence we use LDA in our proposed model.'" onmouseout="this.innerHTML='Однако этот подход не работает так же хорошо, как подход, основанный на LDA, и, следовательно, мы используем LDA в нашей предложенной модели.'">Однако этот подход не работает так же хорошо, как подход, основанный на LDA, и, следовательно, мы используем LDA в нашей предложенной модели.</p>

## Выбор лучшего изображения

<p onmousedown="this.innerHTML='Once the images are clustered, we calculate the within cluster sum of squared Euclidean distance of each image vector with every other image vector in that cluster. This within cluster sum of squared Euclidean distances is used as a metric to choose the best image from each cluster.'" onmouseout="this.innerHTML='Как только изображения кластеризованы, мы вычисляем внутрикластерную сумму квадрата евклидова расстояния каждого вектора изображения с каждым другим вектором изображения в этом кластере. Эта внутрикластреная сумма квадратов евклидовых расстояний используется в качестве метрики для выбора лучшего изображения из каждого кластера.'">Как только изображения кластеризованы, мы вычисляем внутрикластерную сумму квадрата евклидова расстояния каждого вектора изображения с каждым другим вектором изображения в этом кластере. Эта внутрикластреная сумма квадратов евклидовых расстояний используется в качестве метрики для выбора лучшего изображения из каждого кластера.</p>

<p onmousedown="this.innerHTML='We choose the image with the least distance from every other image as a representative of that cluster. From each cluster, we pick such images, hence providing a summary of the entire collection of images. The choosing of an image from each cluster, which represent a distinct kind of images allows us to effectively summarize the images ensuring that the summarized set represents the entire collection well. This is reflected in the high ratings for diversity and coverage. The relatively lower values of the quality metric demonstrates that we can come up with a better metric for choosing the best images from a cluster. However from the experiments we performed, we did not find a metric better than the one we presently use. We are still working on devising better ways of choosing images from a cluster.'" onmouseout="this.innerHTML='Мы выбираем изображение с наименьшим расстоянием от любого другого изображения в качестве представителя этого кластера. Из каждого кластера мы выбираем такие изображения, следовательно, предоставляя сводку всей коллекции изображений. Выбор изображения из каждого кластера, который представляет отдельный вид изображений, позволяет нам эффективно суммировать изображения, гарантируя, что суммарный набор хорошо представляет всю коллекцию. Это отражено в высоких оценках разнообразия и охвата. Относительно более низкие значения показателя качества демонстрируют, что мы можем предложить лучшую метрику для выбора лучших изображений из кластера. Однако из проведенных нами экспериментов мы не нашли метрики лучше той, которую мы используем в настоящее время. Мы все еще работаем над разработкой лучших способов выбора изображений из кластера.'">Мы выбираем изображение с наименьшим расстоянием от любого другого изображения в качестве представителя этого кластера. Из каждого кластера мы выбираем такие изображения, следовательно, предоставляя сводку всей коллекции изображений. Выбор изображения из каждого кластера, который представляет отдельный вид изображений, позволяет нам эффективно суммировать изображения, гарантируя, что суммарный набор хорошо представляет всю коллекцию. Это отражено в высоких оценках разнообразия и охвата. Относительно более низкие значения показателя качества демонстрируют, что мы можем предложить лучшую метрику для выбора лучших изображений из кластера. Однако из проведенных нами экспериментов мы не нашли метрики лучше той, которую мы используем в настоящее время. Мы все еще работаем над разработкой лучших способов выбора изображений из кластера.</p>

<p onmousedown="this.innerHTML='We are also experimenting with various distance metrics. Till now we have tried out Euclidean distance, Manhattan distance, Cosine distance and several other distance metrics. Euclidean distances were found to be giving the best results and hence we persisted with the use of Euclidean distances.'" onmouseout="this.innerHTML='Мы также экспериментировали с различными метриками расстояния. Мы попробовали евклидово расстояние, манхэттенское расстояние, косинусное расстояние и несколько других метрик расстояния. Было обнаружено, что евклидовы расстояния дают наилучшие результаты, и поэтому мы остановились на евклидовом расстоянии.'">Мы также экспериментировали с различными метриками расстояния. Мы попробовали евклидово расстояние, манхэттенское расстояние, косинусное расстояние и несколько других метрик расстояния. Было обнаружено, что евклидовы расстояния дают наилучшие результаты, и поэтому мы остановились на евклидовом расстоянии.</p>

# Результаты и валидация

<p onmousedown="this.innerHTML='We have tested our proposed approach on a sample collection of images from a holiday trip and gave the automatically generated summary to the trip members for validation.'" onmouseout="this.innerHTML='Мы проверили предложенный нами подход на выборочной коллекции изображений из отпуска и предоставили автоматически сгенерированное резюме участникам поездки для проверки.'">Мы проверили предложенный нами подход на выборочной коллекции изображений из отпуска и предоставили автоматически сгенерированное резюме участникам поездки для проверки.</p>

<p onmousedown="this.innerHTML='The sample collection contained 5376 images and through our approach we were able represent the trip by 50 images. The raters are asked to rate the image summary based on 3 parameters namely: Quality, Diversity and Coverage. The 40 trip members were asked to rate the automatically created image summary based on these parameters. We received average ratings of 9.1, 9.5 and 9.4 on a scale of 10 from the trip members for the 3 parameters.'" onmouseout="this.innerHTML='Коллекция образцов содержала 5376 изображений, и благодаря нашему подходу мы смогли описать поездку 50 изображениями. Оценщиков просили оценить суммаризацию изображений на основе 3 параметров, а именно: Качество, Разнообразие и Охват. 40 участников поездки попросили оценить автоматически созданную сводку изображений на основе этих параметров. Мы получили средние оценки 9,1, 9,5 и 9,4 по шкале 10 от участников поездки по 3 параметрам.'">Коллекция образцов содержала 5376 изображений, и благодаря нашему подходу мы смогли описать поездку 50 изображениями. Оценщиков просили оценить суммаризацию изображений на основе 3 параметров, а именно: Качество, Разнообразие и Охват. 40 участников поездки попросили оценить автоматически созданную сводку изображений на основе этих параметров. Мы получили средние оценки 9,1, 9,5 и 9,4 по шкале 10 от участников поездки по 3 параметрам.</p>

<p onmousedown="this.innerHTML='We also asked 500 other members who were not a part of the trip to rate the summary to remove the bias associated with rating ones own images. We received average ratings of 8.9, 9.2 and 9.2 on a scale of 10 from these 500 users for the parameters of Quality, Diversity and Coverage respectively.'" onmouseout="this.innerHTML='Мы также попросили 500 других участников, которые не участвовали в поездке, оценить итоги, чтобы убрать смещение, связанное с оценкой собственных изображений. Мы получили средние оценки 8,9, 9,2 и 9,2 по шкале 10 от этих 500 пользователей по параметрам качества, разнообразия и охвата соответственно.'">Мы также попросили 500 других участников, которые не участвовали в поездке, оценить итоги, чтобы убрать смещение, связанное с оценкой собственных изображений. Мы получили средние оценки 8,9, 9,2 и 9,2 по шкале 10 от этих 500 пользователей по параметрам качества, разнообразия и охвата соответственно.</p>

<p onmousedown="this.innerHTML='For evaluation at a larger and more general set of images we collect the datasets of 20 outdoor activities, consisting of 1.2 millions Flickr images. We allowed the users to control the image summary size. The summaries created by our algorithm were rated by users via crowdsourcing using Amazon Mechanical Turk. We received an average rating of 8.4, 9.0 and 8.9 on a scale of 10 from this crowdsourced grading for the 3 parameters.'" onmouseout="this.innerHTML='Для оценки более широкого и более общего набора изображений мы собирали наборы данных из 20 мероприятий на свежем воздухе, состоящие из 1,2 миллиона изображений Flickr. Мы позволили пользователям контролировать размер изображения - суммаризации. Сводки, созданные по нашему алгоритму, оценивались пользователями посредством краудсорсинга с использованием Amazon Mechanical Turk. Мы получили среднюю оценку 8,4, 9,0 и 8,9 по шкале 10 из этой краудсорсинговой оценки по 3 параметрам.'">Для оценки более широкого и более общего набора изображений мы собирали наборы данных из 20 мероприятий на свежем воздухе, состоящие из 1,2 миллиона изображений Flickr. Мы позволили пользователям контролировать размер изображения - суммаризации. Сводки, созданные по нашему алгоритму, оценивались пользователями посредством краудсорсинга с использованием Amazon Mechanical Turk. Мы получили среднюю оценку 8,4, 9,0 и 8,9 по шкале 10 из этой краудсорсинговой оценки по 3 параметрам.</p>

<p onmousedown="this.innerHTML='The results are tabulated in table I.'" onmouseout="this.innerHTML=''"></p>

<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg .tg-xldj{border-color:inherit;text-align:left}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
</style>
<table class="tg">
  <tr>
    <th class="tg-xldj">Тип коллекции изображений</th>
    <th class="tg-xldj">Размер датасета</th>
    <th class="tg-0pky">Качество</th>
    <th class="tg-0pky">Разнообразие</th>
    <th class="tg-0pky">Сходимость</th>
    <th class="tg-0pky">Среднее</th>
  </tr>
  <tr>
    <td class="tg-xldj">Личные фотографии (оценка теми, кто есть на фотках)</td>
    <td class="tg-xldj">5376</td>
    <td class="tg-0pky">9.1</td>
    <td class="tg-0pky">9.5</td>
    <td class="tg-0pky">9.4</td>
    <td class="tg-0pky">9.3</td>
  </tr>
  <tr>
    <td class="tg-xldj">Личные фотографии (оценка теми, кого нет на фотках)</td>
    <td class="tg-xldj">5376</td>
    <td class="tg-0pky">8.9</td>
    <td class="tg-0pky">9.2</td>
    <td class="tg-0pky">9.2</td>
    <td class="tg-0pky">9.1</td>
  </tr>
  <tr>
    <td class="tg-xldj">Большой общий датасет</td>
    <td class="tg-xldj">1.2 миллиона</td>
    <td class="tg-0pky">9.4</td>
    <td class="tg-0pky">9.0</td>
    <td class="tg-0pky">8.9</td>
    <td class="tg-0pky">8.8</td>
  </tr>
</table>
</center>

<center>Таблица 1. результаты оценки качества</center>

<p onmousedown="this.innerHTML='These results demonstrate that the summary was satisfying for both members and non-members of the image collection. It also demonstrated that the algorithm is scalable to larger image datasets and performs well even on a general collection of images.'" onmouseout="this.innerHTML='Эти результаты демонстрируют, что резюме было удовлетворительным как для людей, связанных с изображений, так и независимых людей. Это также продемонстрировало, что алгоритм масштабируем для больших наборов данных изображений и хорошо работает даже на общей коллекции изображений.'">Эти результаты демонстрируют, что резюме было удовлетворительным как для людей, связанных с изображений, так и независимых людей. Это также продемонстрировало, что алгоритм масштабируем для больших наборов данных изображений и хорошо работает даже на общей коллекции изображений.</p>

# Заключение

<p onmousedown="this.innerHTML='In this project, we have proposed an automatic organization and summarization framework based on SIFT vector representation of an image. Image clusters were obtained through LDA, from which the best image was obtained by choosing the image with minimum sum of squared distance of that image with every other image in its cluster. We haven’t taken into account the timestamps, and have instead used the actual image features to identify similar images extracted by SIFT and accommodated in the model of image selection by Latent Dirichlet Allocation. As is evident from the scores we received from graders for the three metrics of Quality, Diversity and Coverage used for judging image summaries, the model performs fairly well in creating representative summaries of a large image collection both in a personalized and general setting. The ability of the method to scale well for large datasets like the Flickr dataset of 1.2 million images also proves that the method is both effective and time efficient and could be used on larger datasets too.'" onmouseout="this.innerHTML='В этом проекте мы предложили автоматическую систему и суммаризации, основанную на SIFT-векторном представлении изображения. Кластеры изображений были получены с помощью LDA, из которого наилучшее изображение было получено путем выбора изображения с минимальной суммой квадрата расстояния этого изображения со всеми другими изображениями в его кластере. Мы не приняли во внимание временные метки и вместо этого использовали признаки изображения для идентификации похожих изображений, извлеченных с помощью SIFT и размещенных в модели выбора изображений с помощью скрытого распределения Дирихле. Как видно из оценок, которые мы получили от оценщиков по трем показателям качества, разнообразия и охвата, которые использовались для оценки сводок изображений, модель довольно хорошо работает при создании репрезентативных сводок большой коллекции изображений как в персональных, так и в общих изображениях. Способность метода хорошо масштабироваться для больших наборов данных, таких как набор данных Flickr из 1,2 миллиона изображений, также доказывает, что этот метод эффективен и экономичен по времени, и его можно использовать и для больших наборов данных.'">В этом проекте мы предложили автоматическую систему и суммаризации, основанную на SIFT-векторном представлении изображения. Кластеры изображений были получены с помощью LDA, из которого наилучшее изображение было получено путем выбора изображения с минимальной суммой квадрата расстояния этого изображения со всеми другими изображениями в его кластере. Мы не приняли во внимание временные метки и вместо этого использовали признаки изображения для идентификации похожих изображений, извлеченных с помощью SIFT и размещенных в модели выбора изображений с помощью скрытого распределения Дирихле. Как видно из оценок, которые мы получили от оценщиков по трем показателям качества, разнообразия и охвата, которые использовались для оценки сводок изображений, модель довольно хорошо работает при создании репрезентативных сводок большой коллекции изображений как в персональных, так и в общих изображениях. Способность метода хорошо масштабироваться для больших наборов данных, таких как набор данных Flickr из 1,2 миллиона изображений, также доказывает, что этот метод эффективен и экономичен по времени, и его можно использовать и для больших наборов данных.</p>

# Дальнейшая работа

<p onmousedown="this.innerHTML='The present work doesnt take into account personalization of summarization. The summarisation is presently general and doesnt take into account the user preferences.In the future we plan to allow the user to set certain prefer- ences which will control the image summary. For example a particular user may want images of which he is a part of and hence we plan to provide a summary to suit such requests from the user.'" onmouseout="this.innerHTML='Настоящая работа не представляет решения для персонализированных суммаризаций. Обобщение в настоящее время носит общий характер и не учитывает предпочтения пользователя. В будущем мы планируем разрешить пользователю задавать определенные предпочтения, которые будут управлять сводкой изображений. Например, конкретному пользователю могут потребоваться изображения, частью которых он является, и, следовательно, мы планируем предоставить суммаризацию для удовлетворения таких запросов от пользователя.'">Настоящая работа не представляет решения для персонализированных суммаризаций. Обобщение в настоящее время носит общий характер и не учитывает предпочтения пользователя. В будущем мы планируем разрешить пользователю задавать определенные предпочтения, которые будут управлять сводкой изображений. Например, конкретному пользователю могут потребоваться изображения, частью которых он является, и, следовательно, мы планируем предоставить суммаризацию для удовлетворения таких запросов от пользователя.</p>

<p onmousedown="this.innerHTML='Besides the slightly lower value of Quality of the images chosen for the summary prompts us to look for a metric better than the within cluster squared Euclidean distances. We are still experimenting with different metrics for the same and hope that we can find a metric that could improve the quality of images chosen for the summary.'" onmouseout="this.innerHTML='Кроме того, немного более низкое значение метрики качества изображений, выбранных для суммаризации, побуждает нас искать метрику лучше, чем евклидово расстояние в пределах кластера. Мы все еще экспериментируем с разными метриками и надеемся, что сможем найти метрику, которая могла бы повысить метрику качества изображений, выбранных для сводки.'">Кроме того, немного более низкое значение метрики качества изображений, выбранных для суммаризации, побуждает нас искать метрику лучше, чем евклидово расстояние в пределах кластера. Мы все еще экспериментируем с разными метриками и надеемся, что сможем найти метрику, которая могла бы повысить метрику качества изображений, выбранных для сводки.</p>

<p onmousedown="this.innerHTML='We are also looking into better ways to represent an image and extract it’s features as doing so on the basis of SIFT feature vectors alone may not be ideal, as SIFT vectors are invariant to rotation, translation, scaling and partially invariant to illumination changes and affine or 3D projection, which could play a role in choosing the best image.'" onmouseout="this.innerHTML='Мы также ищем более эффективные способы представления изображения и извлечения его признаков, поскольку использование только векторов SIFT может быть не идеальным, поскольку векторы SIFT инвариантны к повороту, перемещению, масштабированию и частично не зависят от изменений освещения и аффинности или 3D-проекции, которые могут сыграть роль в выборе лучшего изображения.'">Мы также ищем более эффективные способы представления изображения и извлечения его признаков, поскольку использование только векторов SIFT может быть не идеальным, поскольку векторы SIFT инвариантны к повороту, перемещению, масштабированию и частично не зависят от изменений освещения и аффинности или 3D-проекции, которые могут сыграть роль в выборе лучшего изображения.</p>

# Благодарности

<p onmousedown="this.innerHTML='We would like to acknowledge the efforts of Dr. Bhiksha Raj and Dr. Rita Singh of Carnegie Mellon University without whose constant support and guidance this project would not have been possible.'" onmouseout="this.innerHTML='Мы хотели бы поблагодарить доктора Бхикшу Радж и доктора Риту Сингх из Университета Карнеги-Меллона, без чьей постоянной поддержки и руководства этот проект был бы невозможен.'">Мы хотели бы поблагодарить доктора Бхикшу Радж и доктора Риту Сингх из Университета Карнеги-Меллона, без чьей постоянной поддержки и руководства этот проект был бы невозможен.</p>

# Список литературы

[1] D. Kirkpatrick, Ed., The Facebook Effect: The Inside Story of the
Company That Is Connecting the World. Simon Schuster, 2010.

[2] D. M. Blei, A. Y. Ng, and M. I. Jordan, “Latent dirichlet allocation,” The Journal of Machine Learning, pp. 993–1022, 2003.

[3] J. Li, J. H. Lim, and Q. Tan, “Automatic summarization for personal digital photos,” Information, Communications and Signal Processing, pp. 1536–1540, 2003.

[4] D. Lowe, “Object recognition from local scale invariant feature,” International Journal of Computer Vision, pp. 91–110, 2004.

[5] K. Toyama, R. Logan, and A. Roseway, “Geographic location tags on digital images,” Proceedings of the 11th ACM Multimedia, pp. 156–166, 2003.

[6] H. Yang and Q.Wang, “Grouping and summarizing scene images from web collections,” Proceedings of the 5th ISVC: Part II, pp. 315–324, 2009.

[7] J. Platt, “Autoalbum: Clustering digital photographs using proba- bilistic model merging,” IEEE Workshop on CAIVL, pp. 96–100, 2000.

[8] M. Cooper, J. Foote, A. Girgensohn, and L. Wilcox, “Temporal event clustering for digital photo colections,” ACM Transaction on MCCA, vol. vol. 1, pp. 269–288, 2005.

[9] A. Graham, H. Garcia-molina, A. Paepcke, and T. Winograd, “Time as essence for photo browsing through personal digital libraries,” Proc. of the 2nd ACM/IEEE-CS JCDL. ACM Press, pp. 326–335, 2002.

[10] M. Boutell and J. Luo, “A generalized temporal context model for semantic scene classification,” IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshop, pp. 104– 112, 2004.

[11] O. Chum and J. Matas, “Large-scale discovery of spatially realted images,” Pattern Analysis and Machine Intelligence, IEEE Trans- actions, pp. 371–377, 2010.

[12] C. Jang, T. Yoon, and H. Cho, “A smart clustering algorithm for photo set obtained from multiple digital camera,” Proceedings of ACM SAC, pp. 1784–1791, 2009.

[13] D. Ryu, S. Park, and H. Cho, “A priority queue-based hierachical photo clustering method using photo timestamps,” IEEE Interna- tional Conference on CSAE, pp. 152–156, 2011.

[14] I. Simon, N. Snavely, and S. Seitz, “Scene summarization for online image collections,” IEEE 11th International Conference on Computer Vision, pp. 1–8, 2007.

[15] P. Sinha and R. Jain, “Extractive summarization of personal photos from life events,” International Conference on Multimedia and Expo (ICME), pp. 1–6, 2011.

[16] P. Sinha, S. Mehrotra, and R. Jain, “Summarization of personal pho- tologs using multidimensional content and context,” International Conference on Multimedia Retrieval (ICMR), pp. 1–8, 2011.

[17] T. Denton, M. Demirci, J. Abrahamson, A. Shokoufandeh, and S. Dickinson, “Selecting canonical views for view-based 3-d object recognition,” Proc. ICPR, p. 273276, 2004.

[18] C. Rother, S. Kumar, V. Kolmogorov, and A. Blake, “Digital tapestry,” Proc. CVPR, pp. 589–596, 2005.

[19] J. Wang, J. Sun, L. Quan, X. Tang, and H. Shum, “Picture collage,” Proc. CVPR, pp. 347–354, 2006.

[20] G. Kim, L. Sigal, and E. Xing, “Joint summarization of large-scale collections of web images and videos for storyline reconstruction,” Proc. CVPR, 2014.

[21] S.Tschiatschek, R. Iyer, H. Wei, and J. Bilmes, “Learning mix- tures of submodular functions for image collection summarization,” dvances of Neural Information Processing Systems (NIPS), 2014.

[22] A. Jaffe, M. Naaman, T. Tassa, and M. Davis, “Generating sum- maries for large collections of geo-referenced photographs,” Proc. Int. Conf. on World Wide Web, pp. 853–854, 2006.

[23] P. Schmitz, “Inducing ontology from flickr tags,” Collaborative Web Tagging Workshop at WWW, 2006.

[24] D. Lowe, “Distinctive image features from scale invariant key- points,” International Journal of Computer Vision, pp. 91–110, 2004.

[25] K. Peker, “Binary sift: Fast image retrieval using binary qunatized sift features,” 9th International Workshop on CBMI, pp. 217–222, 2011.

[26] H. Lee, J. Kihm, J. Choo, J. Stasko, and H. Park, “ivisclustering: An interactive visual document clustering via topic modeling,” Eurographics Conference on Visualization (EuroVis), vol. 31, 2012.

[27] P. Xie and E. Xing, “Integrating document clustering and topic modeling,” CoRR, vol. abs/1309.6874, 2013.

[28] C. Elkan, “Clustering documents with an exponential-family ap- proximation of the dirichlet compound multinomial distribution,” in In ICML, 2006, pp. 289–296.
